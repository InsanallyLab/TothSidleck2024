{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0f552-b1ee-4854-a98a-27bd55451c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815b713e-aaa2-4fa9-a21d-1b2c71799dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import json, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time as pytime\n",
    "import statsmodels.tsa.stattools as tsa\n",
    "import ruptures as rpt\n",
    "sys.path.append('../..')\n",
    "import InsanallyLabEphysTools as ilep\n",
    "from scipy.stats import gaussian_kde, sem, ttest_ind, ttest_rel, norm, mannwhitneyu, linregress, wilcoxon\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "from itertools import product\n",
    "from brokenaxes import brokenaxes\n",
    "import pingouin as pg\n",
    "import colorsys\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 'small'\n",
    "plt.rcParams['axes.labelsize'] = 'medium'\n",
    "plt.rcParams['axes.formatter.limits'] = [-2,3]\n",
    "plt.rcParams['axes.formatter.use_mathtext'] = True\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['figure.dpi'] = '150'\n",
    "\n",
    "#Set global font parameters\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "#Set font type to TrueType for compatibility\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "TARGET_COLOR = '#ff3654'\n",
    "NONTARGET_COLOR = '#5776ff'\n",
    "\n",
    "CR_COLOR = '#808080'\n",
    "NCR_COLOR = '#FF767C'\n",
    "CNO_COLOR = '#00BFFF'\n",
    "SWITCH_COLOR = '#B07A3B'\n",
    "LASER_COLOR = '#3375E9'\n",
    "GOOD_GREY = '#969696'\n",
    "GOOD_GREEN = '#32A852'\n",
    "NCR_COLOR_DESAT = '#D98C90'\n",
    "CR_COLOR_DESAT = '#A0A0A0'\n",
    "NCR_CR_cmap = mpl.colors.LinearSegmentedColormap.from_list('NCR-CR color map', [NCR_COLOR, CR_COLOR], N=1000)\n",
    "PHASE_COLORS = ['#DEB9E0','#B78AB9','#906D92','#ABC5E8','#869BB7','#5E6C80']#,'#6ded94','#50d979','#36bf5f']\n",
    "\n",
    "\n",
    "did_not_learn_animals = ['BS_86','BS_100','BS_119','BS_123','BS_128','BS_131','BS_163','BS_174']\n",
    "dualanimalnames = ['BS_40','BS_41','BS_42','BS_49','BS_50','BS_51','BS_56','BS_59','BS_67','BS_70','BS_72','BS_87','BS_108']#,'DS_15','DS_19']\n",
    "\n",
    "\n",
    "#act_directory = 'D:\\\\Analysis_Cache_archived_Oct_27_2022'\n",
    "act_directory = '..\\\\..\\\\Data\\\\Analysis_Cache'\n",
    "ops_directory = '..\\\\..\\\\Data\\\\Opsin_Cache'\n",
    "beh_directory = '..\\\\..\\\\Data\\\\Behavioor'\n",
    "\n",
    "stim25sdecodingfilename = '..\\\\..\\\\Data\\\\stimdecoding_25s.csv'\n",
    "stim25sopsinondecodingfilename = '..\\\\..\\\\Data\\\\stimdecoding_25s_opsin_on.csv'\n",
    "stim25sopsinoffdecodingfilename = '..\\\\..\\\\Data\\\\stimdecoding_25s_opsin_off.csv'\n",
    "\n",
    "current_version = 1 #Aug 12th, 2023\n",
    "\n",
    "stdfont = 14\n",
    "stdyfrac = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefeb26d-c150-48eb-a0ec-b408e3ab9b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46dab197-4c36-4217-833d-00372493dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = np.concatenate((dualanimalnames,['DS_15','DS_19','AE_267']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54464c-fc31-4c50-8158-ab8ecad9d2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching files for BS_51\n",
      "Fetching files for BS_52\n",
      "Fetching files for BS_56\n",
      "Fetching files for BS_59\n",
      "Fetching files for BS_61\n",
      "Fetching files for BS_86\n",
      "Fetching files for BS_92\n",
      "Fetching files for BS_100\n",
      "Fetching files for BS_103\n",
      "Fetching files for BS_111\n",
      "Fetching files for BS_119\n",
      "Fetching files for BS_123\n",
      "Fetching files for BS_128\n",
      "Fetching files for BS_131\n",
      "Fetching files for BS_139\n",
      "Fetching files for BS_163\n",
      "Fetching files for BS_165\n",
      "Fetching files for BS_174\n",
      "Fetching files for BS_179\n",
      "Fetching files for BS_191\n",
      "Fetching files for BS_192\n",
      "Fetching files for BS_33\n",
      "Fetching files for BS_67\n",
      "Fetching files for BS_73\n",
      "Fetching files for BS_78\n",
      "Fetching files for BS_108\n",
      "Fetching files for BS_40\n",
      "Fetching files for BS_41\n",
      "Fetching files for BS_42\n",
      "Fetching files for BS_49\n",
      "Fetching files for BS_50\n",
      "Fetching files for BS_70\n",
      "Fetching files for BS_72\n",
      "Fetching files for BS_83\n",
      "Fetching files for BS_85\n",
      "Fetching files for BS_87\n",
      "Fetching files for BS_95\n",
      "Fetching files for BS_113\n",
      "Fetching files for DS_15\n",
      "Fetching files for DS_16\n",
      "Fetching files for DS_17\n",
      "Fetching files for DS_19\n",
      "Fetching files for DS_22\n",
      "Fetching files for DS_23\n",
      "Fetching files for DS_24\n",
      "Fetching files for DS_27\n",
      "Fetching files for DS_28\n",
      "Fetching files for DS_13\n",
      "Fetching files for BS_173\n",
      "Fetching files for BS_175\n",
      "Fetching files for BS_187\n",
      "Fetching files for BS_188\n",
      "Fetching files for BS_213\n",
      "Fetching files for BS_214\n",
      "Fetching files for TH_217\n",
      "Fetching files for AE_235\n",
      "Fetching files for AE_236\n",
      "Fetching files for TH_237\n",
      "Fetching files for AE_252\n",
      "Fetching files for AE_254\n",
      "Fetching files for AE_238\n",
      "Fetching files for AE_239\n",
      "Fetching files for AE_240\n",
      "Fetching files for AE_267\n",
      "Fetching files for AO_273\n",
      "Fetching files for AO_274\n",
      "Fetching files for AE_287\n",
      "Fetching files for AE_301\n",
      "Fetching files for AE_312\n",
      "..\\..\\Data\\Behavioor\\BS_61\\behavior\\BS_61_42v2_reversal.txt: No columns to parse from file\n",
      "..\\..\\Data\\Behavioor\\BS_103\\behavior\\BS_103_11v4_opto.txt: No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "animalBehaviors = ilep.getAllBehavior(beh_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c89f7f-ec3f-4691-9599-f7b346d64c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_phases,_,_ = ilep.calculateLearningPhasesV2(animals,animalBehaviors,plot=True)\n",
    "#plt.savefig(os.path.join('D:\\\\\\\\TempFigures','All ephys animals learning phases.pdf'),transparent=False,facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9acc7-7a87-44ac-a766-5d7815c7dd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EnumSession = []\n",
    "EnumClust = []\n",
    "sessions = os.listdir(act_directory)\n",
    "for session in tqdm(sessions):\n",
    "    sessionfile = ilep.loadSessionCached(act_directory,session)\n",
    "    \n",
    "    if sessionfile.meta.task in ['passive no beahvior']:\n",
    "        continue\n",
    "    if sessionfile.meta.task in ['tuning nonreversal','tuning switch','tuning reversal']:\n",
    "        continue\n",
    "    if sessionfile.meta.region != 'AC':\n",
    "        continue\n",
    "        \n",
    "    if sessionfile.meta.animal not in animals:\n",
    "        continue\n",
    "    \n",
    "    for clust in sessionfile.clusters.good:\n",
    "        EnumSession.append(session)\n",
    "        EnumClust.append(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade915d-57ef-497a-b4de-713f30a3093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EILphases = np.full_like(EnumSession,np.nan)\n",
    "error_animals = []\n",
    "\n",
    "for idx,session in enumerate(tqdm(EnumSession)):\n",
    "    sessionfile = ilep.loadSessionCached(act_directory,session)\n",
    "    \n",
    "    try:\n",
    "        animal = sessionfile.meta.animal\n",
    "        day = sessionfile.meta.day_of_training\n",
    "        \n",
    "        if sessionfile.meta.task in ['switch','opto switch','tuning switch']:\n",
    "            EILphases[idx] = 'switch'\n",
    "\n",
    "        elif sessionfile.meta.task in ['nonreversal','opto nonreversal','tuning nonreversal'] and day in learning_phases[animal].pre_early_days:\n",
    "            EILphases[idx] = 'pre early'\n",
    "        elif sessionfile.meta.task in ['nonreversal','opto nonreversal','tuning nonreversal']  and day in learning_phases[animal].pre_late_days:\n",
    "            EILphases[idx] = 'pre late'\n",
    "        elif sessionfile.meta.task in ['nonreversal','opto nonreversal','tuning nonreversal'] and day in learning_phases[animal].pre_expert_days:\n",
    "            EILphases[idx] = 'pre expert'\n",
    "\n",
    "        elif sessionfile.meta.task in ['reversal','opto reversal','tuning reversal']  and day in learning_phases[animal].post_early_days:\n",
    "            EILphases[idx] = 'post early'\n",
    "        elif sessionfile.meta.task in ['reversal','opto reversal','tuning reversal']  and day in learning_phases[animal].post_late_days:\n",
    "            EILphases[idx] = 'post late'\n",
    "        elif sessionfile.meta.task in ['reversal','opto reversal','tuning reversal']  and day in learning_phases[animal].post_expert_days:\n",
    "            EILphases[idx] = 'post expert'\n",
    "    except Exception as e:\n",
    "        #print(ilep.generateDateString(sessionfile))\n",
    "        error_animals.append(sessionfile.meta.animal)\n",
    "        pass\n",
    "                             \n",
    "error_animals = np.unique(error_animals)\n",
    "print('errors for: '+str(error_animals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb510e-72f4-4e29-97a1-06d3774878d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2e783-a363-460c-8a67-6fccb5b37c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6151ebb-1469-4505-a013-9aa34825bd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51dd82fe-8b9b-49c5-8a18-4056a76c3b94",
   "metadata": {},
   "source": [
    "# Stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ca396-1510-4c48-96fd-4670b413968b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this function calculates pval for one cluster(one cell)\n",
    "def calculate_NCR_CR_pval(sessionfile,clust):\n",
    "\n",
    "    #convert window(100ms) in samples\n",
    "    sessionfile.meta.fs #30000 samples / second from blackrock\n",
    "    window = sessionfile.meta.fs * 0.1\n",
    "    trials_to_use = sessionfile.trim[clust].trimmed_trials\n",
    "\n",
    "    #create array for stimulus period\n",
    "    #tone play start time\n",
    "    onset_window_start_time = np.zeros(len(trials_to_use))\n",
    "    for idx, trial in enumerate(trials_to_use):\n",
    "        onset_window_start_time[idx] = sessionfile.trials.starts[trial]\n",
    "\n",
    "    #tone play end time\n",
    "    onset_window_end_time = onset_window_start_time + window\n",
    "    #offset window start time\n",
    "    offset_window_start_time = onset_window_end_time\n",
    "    #offset window end time\n",
    "    offset_window_end_time = offset_window_start_time + window\n",
    "    #stimulus array\n",
    "    stimulus_array = np.zeros([len(onset_window_start_time),2,2])\n",
    "    for i in range(len(onset_window_start_time)):\n",
    "        stimulus_array[i] = [[onset_window_start_time[i],onset_window_end_time[i]],\n",
    "                             [offset_window_start_time[i],offset_window_end_time[i]]\n",
    "                            ]\n",
    "\n",
    "    #create array for baseline period\n",
    "    base_window1_start = onset_window_start_time - 3*window\n",
    "    base_window1_end = onset_window_start_time - 2*window\n",
    "    base_window2_start = base_window1_end\n",
    "    base_window2_end = onset_window_start_time - 1*window\n",
    "    base_window3_start = base_window2_end\n",
    "    base_window3_end = onset_window_start_time\n",
    "\n",
    "    baseline_array = np.zeros([len(base_window1_start),3,2])\n",
    "    for i in range(len(onset_window_start_time)):\n",
    "        baseline_array[i] = [[base_window1_start[i],base_window1_end[i]],\n",
    "                             [base_window2_start[i],base_window2_end[i]],\n",
    "                             [base_window3_start[i],base_window3_end[i]],\n",
    "                            ]\n",
    "\n",
    "    #evaluate spike count within stimulus window\n",
    "    spikecounts_stimuluswindow = np.zeros((len(onset_window_start_time),2))\n",
    "\n",
    "    for idx, t in enumerate(stimulus_array):\n",
    "        #print(t[0][0])\n",
    "\n",
    "        #spike count from onset window\n",
    "        spikecount_onsetwindow = len(ilep.getSpikeTimes(sessionfile,clust=clust,starttime=t[0][0],endtime=t[0][1]))\n",
    "\n",
    "        #spike count from offset window\n",
    "        spikecount_offsetwindow = len(ilep.getSpikeTimes(sessionfile,clust=clust,starttime=t[1][0],endtime=t[1][1]))\n",
    "\n",
    "        spikecounts_stimuluswindow[idx][0]=spikecount_onsetwindow\n",
    "        spikecounts_stimuluswindow[idx][1]=spikecount_offsetwindow\n",
    "\n",
    "    #evaluate spike count within baseline window\n",
    "    spikecounts_basewindow = np.zeros((len(onset_window_start_time),3))\n",
    "\n",
    "    for idx, t in enumerate(baseline_array):\n",
    "        #print(t[0][0])\n",
    "\n",
    "        #spike count from window1\n",
    "        spikecount_base_window1 = len(ilep.getSpikeTimes(sessionfile,clust=clust,starttime=t[0][0],endtime=t[0][1]))\n",
    "\n",
    "        #spike count from window2\n",
    "        spikecount_base_window2 = len(ilep.getSpikeTimes(sessionfile,clust=clust,starttime=t[1][0],endtime=t[1][1]))\n",
    "\n",
    "        #spike count from window3\n",
    "        spikecount_base_window3 = len(ilep.getSpikeTimes(sessionfile,clust=clust,starttime=t[2][0],endtime=t[2][1]))\n",
    "\n",
    "        spikecounts_basewindow[idx][0]=spikecount_base_window1\n",
    "        spikecounts_basewindow[idx][1]=spikecount_base_window2\n",
    "        spikecounts_basewindow[idx][2]=spikecount_base_window3\n",
    "\n",
    "    ###### CODE BELOW HERE SHOULD LOOP 5000 TIMES \n",
    "    iterations = 5000\n",
    "    #spikecounts_diff_mean_arr = []\n",
    "\n",
    "    CR_evok_appear=0\n",
    "    CR_sup_appear=0\n",
    "    NCR_appear=0\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        #1.subsampled 90% of the spike count changes from baseline,\n",
    "        #2.calculated the mean of these values, repeated this process 5000 times \n",
    "\n",
    "        #1.\n",
    "        #subsampled 90% trials\n",
    "        trials = range(len(spikecounts_stimuluswindow))\n",
    "        trials_perm = np.random.permutation(trials)\n",
    "        trials_subsamp = trials_perm[range(int(0.9*len(trials_perm)))]\n",
    "\n",
    "        #calculate spike count changes from baseline in the subsample\n",
    "        spikecounts_diff = []\n",
    "        for trial_idx in trials_subsamp:\n",
    "            random_stimulus = spikecounts_stimuluswindow[trial_idx][np.random.randint(2)]\n",
    "            random_base = spikecounts_basewindow[trial_idx][np.random.randint(3)]\n",
    "            spikecounts_diff.append(random_stimulus-random_base)\n",
    "\n",
    "        #2. \n",
    "        #calculate the mean of the spike counts diff  \n",
    "        spikecounts_diff_mean = np.mean(spikecounts_diff)\n",
    "        #calculate the # of appearance in each categotiry in 5000 iterations\n",
    "        if spikecounts_diff_mean > 0.1:\n",
    "            CR_evok_appear+=1\n",
    "        elif spikecounts_diff_mean < -0.1:\n",
    "            CR_sup_appear+=1\n",
    "        else:\n",
    "            NCR_appear+=1\n",
    "            \n",
    "    p_value_evoked = CR_evok_appear/(iterations)\n",
    "    p_value_suppressed = CR_sup_appear/(iterations)\n",
    "    p_value_NCR = NCR_appear/(iterations)\n",
    "    return p_value_evoked, p_value_suppressed, p_value_NCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f187e3-615e-40aa-ab83-a0bedc85f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_list = []\n",
    "session_list = []\n",
    "cluster_ID_list = []\n",
    "FRmod_list = []\n",
    "category_list = []\n",
    "\n",
    "for idx,(session,clust) in tqdm(enumerate(zip(EnumSession,EnumClust))):\n",
    "    sessionfile = ilep.loadSessionCached(act_directory,session)\n",
    "    \n",
    "    if EILphases[idx] not in ['pre early','pre late','pre expert','post early','post late','post expert']:\n",
    "        continue\n",
    "    if sessionfile.meta.animal not in dualanimalnames:\n",
    "        continue\n",
    "    \n",
    "    p_evk,p_sup,p_ncr = calculate_NCR_CR_pval(sessionfile,clust)\n",
    "\n",
    "    try:\n",
    "        FRmod = sessionfile.responsiveness[clust]['all_trials'].FRmodulation\n",
    "    except Exception as e:\n",
    "        FRmod=np.nan\n",
    "        print(e)\n",
    "    if not np.isfinite(FRmod):\n",
    "        continue\n",
    "\n",
    "    category = 'N/A'\n",
    "    if p_evk >= 0.95:\n",
    "        category = 'CR (enhanced)'\n",
    "    elif p_sup >= 0.95:\n",
    "        category = 'CR (suppressed)'\n",
    "    elif p_ncr >= 0.95:\n",
    "        category = 'NCR'\n",
    "    else:\n",
    "        category = 'Inconclusive'\n",
    "\n",
    "    animal_list.append(sessionfile.meta.animal)\n",
    "    session_list.append(session)\n",
    "    cluster_ID_list.append(clust)\n",
    "    FRmod_list.append(FRmod)\n",
    "    category_list.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033fe34-d2f0-4c1c-95d2-01f00e3a2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "df_dict['animal'] = animal_list\n",
    "df_dict['session'] = session_list\n",
    "df_dict['cluster ID'] = cluster_ID_list\n",
    "df_dict['FR modulation'] = FRmod_list\n",
    "df_dict['category'] = category_list\n",
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a1955-f17f-4ac4-9a8b-e72ad4ce111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3edbcd-1842-43e8-989a-058db96061cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('..\\\\..\\\\Source Data Files\\EDF 5a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43e10f-d96a-4fca-bf54-4270010bb20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40551588-fe07-4f87-b222-d118965524f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad42a7-3be2-4ae8-988f-3a963b7d48c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed383d-3824-4c8b-a9e6-28b093d2b0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe9f02-ef2c-4069-85d0-8ec0427c06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmod_evoked = []\n",
    "FRmod_suppressed = []\n",
    "FRmod_NCR = []\n",
    "FRmod_inc = []\n",
    "\n",
    "df_evoked = df[df['category']=='CR (enhanced)']\n",
    "FRmod_evoked = df_evoked['FR modulation'].values\n",
    "\n",
    "df_suppressed = df[df['category']=='CR (suppressed)']\n",
    "FRmod_suppressed = df_suppressed['FR modulation'].values\n",
    "\n",
    "df_NCR = df[df['category']=='NCR']\n",
    "FRmod_NCR = df_NCR['FR modulation'].values\n",
    "\n",
    "df_inc = df[df['category']=='Inconclusive']\n",
    "FRmod_inc = df_inc['FR modulation'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528935cf-dd8b-4ff8-9daa-c3d29c6aa271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c05561-7815-4244-a627-edbc55cdb415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15daf9a-6fbe-4784-a1d3-053b971638ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c2340-4d42-43a5-b734-c9b4a952bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_axis_size(fig, ax_w, ax_h, left, bottom):\n",
    "    fig_w, fig_h = fig.get_size_inches()\n",
    "    ax = fig.add_axes([left/fig_w, bottom/fig_h, ax_w/fig_w, ax_h/fig_h])\n",
    "    return ax\n",
    "\n",
    "def make_axis_size(ax_w, ax_h, left=.3, bottom=.3, right=0, top=0):\n",
    "    fig_w = (ax_w + left + right) * 1.05\n",
    "    fig_h = (ax_h + bottom + top) * 1.05\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    ax = add_axis_size(fig, ax_w, ax_h, left, bottom)\n",
    "    return fig, ax\n",
    "\n",
    "fig,ax = make_axis_size(3, 4, left=.3, bottom=.3, right=0, top=0)\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "X,Y = ilep.violin(FRmod_NCR,log=True)\n",
    "ax.scatter(X,Y,s=5,color=NCR_COLOR)\n",
    "\n",
    "X,Y = ilep.violin(np.concatenate((FRmod_evoked,FRmod_suppressed)),log=True)\n",
    "ax.scatter(X+1,Y,s=5,color=CR_COLOR)\n",
    "\n",
    "X,Y = ilep.violin(FRmod_inc,log=True)\n",
    "ax.scatter(X+2,Y,s=5,color='k')\n",
    "\n",
    "ax.axhline(2.9034419036315477,linestyle='--',color='k',zorder=-10,label='CR/NCR Threshold')\n",
    "# ax.axhline(2.9,linestyle='--',color='k',zorder=-10,label='CR/NCR Threshold')\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "labels = ['NCR','CR','Inc.']\n",
    "\n",
    "ax.set_yscale('log',subs=[])\n",
    "ax.set_ylim([0.1,100])\n",
    "ax.set_yticks([0.1,1,10,100])\n",
    "ax.set_yticklabels(['0.1','1','10','100'])\n",
    "ylab = ax.set_ylabel('Firing rate modulation (spikes/s)')\n",
    "\n",
    "ax.set_xlim([-0.5,2.5])\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(labels)\n",
    "# xlab = ax.set_xlabel('Example X label')\n",
    "\n",
    "# xtick_pos_pre = ax.get_xticks()[1]\n",
    "# xtick_pos_post = ax.get_xticks()[4]\n",
    "# Yval = ilep.getPrePostLabelYval(ax.get_ylim(),Yfrac=-2*stdyfrac)\n",
    "# t1 = ax.text(xtick_pos_pre, Yval, 'Pre-rev', ha='center', va='bottom', fontsize=stdfont,color='k')\n",
    "# t2 = ax.text(xtick_pos_post, Yval, 'Post-rev', ha='center', va='bottom',  fontsize=stdfont,color='k')\n",
    "# ax.annotate('', xy=(0.03, -stdyfrac), xycoords='axes fraction', xytext=(0.49, -stdyfrac),arrowprops=dict(arrowstyle='-', color='black'))\n",
    "# ax.annotate('', xy=(0.53, -stdyfrac), xycoords='axes fraction', xytext=(0.99, -stdyfrac),arrowprops=dict(arrowstyle='-', color='black'))\n",
    "\n",
    "ax.tick_params(direction='in', length=6, width=1)\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "    ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(stdfont)\n",
    "for item in (ax.get_xticklabels()):\n",
    "    item.set_fontsize(stdfont*0.9)\n",
    "    pass\n",
    "\n",
    "lgd = ax.legend(frameon=False,loc=(0.7,.9))\n",
    "\n",
    "### Log\n",
    "# Y = 10**np.mean(np.log10(ax.get_ylim()))\n",
    "# t = ax.text(2.5,Y,'Reversal',rotation=90,fontsize=stdfont,color=SWITCH_COLOR,horizontalalignment='center',verticalalignment='center')\n",
    "# ax.plot([2.5]*2,[ax.get_ylim()[0],Y*0.45],lw=1,color=SWITCH_COLOR)\n",
    "# ax.plot([2.5]*2,[ax.get_ylim()[1],Y/0.45],lw=1,color=SWITCH_COLOR)\n",
    "\n",
    "### Linear\n",
    "# Y = np.mean(ax.get_ylim())\n",
    "# t = ax.text(2.5,Y,'Reversal',rotation=90,fontsize=stdfont,color=SWITCH_COLOR,horizontalalignment='center',verticalalignment='center')\n",
    "# ax.plot([2.5]*2,[ax.get_ylim()[0],Y-np.ptp(ax.get_ylim())*0.125],lw=1,color=SWITCH_COLOR)\n",
    "# ax.plot([2.5]*2,[ax.get_ylim()[1],Y+np.ptp(ax.get_ylim())*0.125],lw=1,color=SWITCH_COLOR)\n",
    "\n",
    "artists = [ylab,lgd]\n",
    "# fig.savefig(os.path.join('D:\\\\\\\\Figures','Manuscript Figures','CR NCR Threshold Schematic V'+str(current_version)+'.pdf'),transparent=False,facecolor=\"white\",dpi=400, bbox_extra_artists=(artists), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc191e75-f0f4-43fd-bb72-4af03dad70a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba4039-f70a-42ec-98eb-16d7c139ba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3915d-02e8-40e1-93f8-a105cc6709b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod_NCR = ilep.rmnan(np.abs(FRmod_NCR))\n",
    "Mod_CR = np.concatenate((ilep.rmnan(np.abs(FRmod_evoked)),ilep.rmnan(np.abs(FRmod_suppressed))))\n",
    "\n",
    "Mod_NCR = np.vstack((Mod_NCR,np.zeros_like(Mod_NCR))).T\n",
    "Mod_CR = np.vstack((Mod_CR,np.zeros_like(Mod_CR))).T\n",
    "\n",
    "X = np.r_[Mod_NCR,Mod_CR]\n",
    "Y = np.r_[np.zeros(len(Mod_NCR)),np.ones(len(Mod_CR))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f112f43-0138-45fe-ad1e-993b737dbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, Y)\n",
    "w = clf.coef_[0]\n",
    "x_0 = -clf.intercept_[0]/w[0]\n",
    "margin = w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c9c79-d88d-40b6-943e-cc02e1436f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bae3f3-56e3-4d9d-ba4f-e09cb7aec053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700631-91ac-4c0b-8f47-3f45d88f4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe948a-73a2-4dba-a53d-36fcfbf73028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
